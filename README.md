# DA6401_Intro_to_DeepLearning_Assignment_2

## ðŸ“ Project Overview

This repository contains a complete implementation for the iNaturalist 12K classification assignment for course: DA6401 Introduciton to Deep Learning, IIT Madras. It covers:

- **PartÂ A**: Training a custom CNN from scratch, including hyperparameter sweeps.
- **PartÂ B**: Fineâ€‘tuning a preâ€‘trained ResNetâ€‘50 with a progressive freeze/unfreeze strategy.

The codebase is organized into Python modules, YAML configuration files, and Jupyter notebooks for interactive exploration.

Please find Wandb Report [here](https://wandb.ai/da24s020-indian-institute-of-technology-madras/DA6401_Intro_to_DeepLearning_Assignment_2/reports/DA6401-Assignment-2--VmlldzoxMjMxODA4Mw?accessToken=n3jv7pu7k48k0q6503sooe6jfvn4sjjlepamilnanl3m97fckdx39mudcmb1xpqv)

---

## ðŸ“‚ Directory Structure

```
DA6401_Intro_to_DeepLearning_Assignment_2/
â”œâ”€ config/
â”‚  â”œâ”€ configs.yaml         # Static configs for each solution
â”‚  â””â”€ sweep_config.yaml    # W&B sweep hyperparameter grid
â”‚
â”œâ”€ data/
â”‚  â””â”€ data_loader.py       # Lightning and custom DataLoader utilities
â”‚
â”œâ”€ models/
â”‚  â”œâ”€ implementation.py    # MyCNN and MyCNNExtended architectures
â”‚  â””â”€ wrapper.py           # PyTorch Lightning wrapper (LitInatModel)
â”‚
â”œâ”€ notebooks/
â”‚  â”œâ”€ partA.ipynb          # Interactive walkthrough for PartÂ A
â”‚  â”œâ”€ partB.ipynb     # Interactive walkthrough for PartÂ B
â”‚
â”œâ”€ partA/
â”‚  â”œâ”€ solution_1.py        # Single-image inference (MyCNN)
â”‚  â”œâ”€ solution_2.py        # Hyperparameter sweep with MyCNNExtended
â”‚  â””â”€ solution_4.py        # Best-from-scratch training & evaluation
â”‚
â”œâ”€ partB/
â”‚  â””â”€ solution_3.py        # Progressive fineâ€‘tuning of ResNetâ€‘50
â”‚
â”œâ”€ utils/
â”‚  â”œâ”€ common_utils.py      # Seed setting, config loader, activation lookup
â”‚  â”œâ”€ data_utils.py        # Single-image loader & helpers
â”‚  â””â”€ model_utils.py       # Train/validate loops & test evaluation
â”‚
â””â”€ outputs/
   â”œâ”€ partA_Q4_best_model.pth
   â”œâ”€ partA_Q4_test_predictions_grid.png
   â””â”€ partB_Q3_best_resnet50.pth
```

---

## âš™ï¸ Installation & Dependencies

1. **Create a Conda or virtualenv** with PythonÂ 3.8+.
2. **Install required packages:**
   ```bash
   pip install torch torchvision pytorch-lightning wandb scikit-learn matplotlib pyyaml
   ```
3. **Setup W&B** (if using sweep and logging):
   ```bash
   wandb login  # follow prompt to paste your API key
   ```

---

## ðŸ”§ Configuration

All paths, hyperparameters, and dataset locations are managed via `config/configs.yaml`:

- **PartÂ A** (scratch): under `part_a_configs` â†’ `solution_1_configs`, `solution_2_configs`, `solution_4_configs`.
- **PartÂ B** (fineâ€‘tune): under `part_b_configs` â†’ `solution_3_configs`.

A separate `config/sweep_config.yaml` defines the W&B hyperparameter grid for PartÂ A sweep.

---

## ðŸš€ Running the Code

### 1) PartÂ A: From Scratch

**SolutionÂ 1** â€“ Singleâ€‘image inference with `MyCNN`:
```bash
python partA/solution_1.py
```

**SolutionÂ 2** â€“ Hyperparameter sweep with `MyCNNExtended` (W&B):
```bash
python partA/solution_2.py
```
> This script will create a sweep, run `sweep_train()` for each trial, then produce a correlation matrix in W&B.

**SolutionÂ 4** â€“ Train the best scratch CNN & evaluate:
```bash
python partA/solution_4.py
```
> Outputs: checkpoint `outputs/partA_Q4_best_model.pth` and prediction grid image.

---

### 2) PartÂ B: Fineâ€‘Tuning Preâ€‘trained ResNetâ€‘50

**SolutionÂ 3** â€“ Progressive freeze/unfreeze fineâ€‘tuning:
```bash
python partB/solution_3.py
```
> Outputs: checkpoint `outputs/partB_Q3_best_resnet50.pth`, W&B logs, and confusion matrix.

---

## ðŸ“Š Evaluation & Results

- **Scratch CNN** (PartÂ A Q4): ~**42.65â€¯%** test accuracy on iNaturalistâ€‘10 subset.
- **Fineâ€‘tuned ResNetâ€‘50** (PartÂ B Q3): ~**90.75â€¯%** test accuracy.

All training/validation curves and confusion matrices are logged to W&B under the specified project names.

---

## ðŸ““ Jupyter Notebooks

For an **interactive walkthrough**, open:
- `notebooks/partA.ipynb` â€“ covers data loading, model definition, training loops for PartÂ A.
- `notebooks/partB.ipynb` â€“ covers data loading, model definition, training loops for PartÂ B.

---

## ðŸ“– Further Notes

- Ensure the dataset is unzipped under `inaturalist_data/nature_12K_extracted/` with `train/`, and `test/` folders.
- Adjust `CUDA_VISIBLE_DEVICES` in each script to match your GPU setup.
- Use `utils/common_utils.py` to modify random seed or activation mappings globally.

---

**Authors:** Kaushik Doddamani, IITâ€¯Madras 2024â€“25

**License:** MIT

